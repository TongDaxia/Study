<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>铜色记忆</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="技术的世界也可以精彩而有趣">
<meta name="keywords" content="java 开发">
<meta property="og:type" content="website">
<meta property="og:title" content="铜色记忆">
<meta property="og:url" content="https://tongdaxia.github.io/index.html">
<meta property="og:site_name" content="铜色记忆">
<meta property="og:description" content="技术的世界也可以精彩而有趣">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="铜色记忆">
<meta name="twitter:description" content="技术的世界也可以精彩而有趣">
  
    <link rel="alternate" href="/atom.xml" title="铜色记忆" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">铜色记忆</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">记录有意思的事情</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://tongdaxia.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-JVM调优" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/05/22/JVM调优/" class="article-date">
  <time datetime="2019-05-22T00:20:18.475Z" itemprop="datePublished">2019-05-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="JVM调优"><a href="#JVM调优" class="headerlink" title="JVM调优"></a>JVM调优</h1><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>基本类型和引用类型</p>
<h2 id="堆与栈"><a href="#堆与栈" class="headerlink" title="堆与栈"></a>堆与栈</h2><p>​    栈是<strong>运行时的单位</strong>，而堆是<strong>存储的单位</strong>。</p>
<p>​    栈解决程序的运行问题，即程序如何执行，或者说如何处理数据；堆解决的是数据存储的问题，即数据怎么放、放在哪儿。</p>
<p>​    在Java中一个线程就会相应有一个线程栈与之对应，这点很容易理解，因为不同的线程执行逻辑有所不同，因此需要一个独立的线程栈。而堆则是所有线程共享的。栈因为是运行单位，因此里面存储的信息都是跟当前线程（或程序）相关信息的。包括局部变量、程序运行状态、方法返回值等等；而堆只负责存储对象信息。</p>
<h6 id="为什么要把堆和栈区分的原因："><a href="#为什么要把堆和栈区分的原因：" class="headerlink" title="为什么要把堆和栈区分的原因："></a>为什么要把堆和栈区分的原因：</h6><p><strong>第一</strong>，从软件设计的角度看，<strong>栈代表了处理逻辑，而堆代表了数据</strong>。这样分开，使得处理逻辑更为清晰。分而治之的思想。这种隔离、模块化的思想在软件设计的方方面面都有体现。</p>
<p><strong>第二</strong>，堆与栈的分离，使得<strong>堆中的内容可以被多个栈共享</strong>（也可以理解为多个线程访问同一个对象）。这种共享的收益是很多的。一方面这种共享提供了一种有效的数据交互方式(如：共享内存)，另一方面，堆中的共享常量和缓存可以被所有栈访问，节省了空间。</p>
<p><strong>第三</strong>，栈因为运行时的需要，比如保存系统运行的上下文，需要进行地址段的划分。由于栈只能向上增长，因此就会限制住栈存储内容的能力。而堆不同，堆中的对象是可以根据需要动态增长的，因此栈和堆的拆分，使得<strong>动态增长成为可能</strong>，相应栈中只需记录堆中的一个地址即可。</p>
<p><strong>第四</strong>，面向对象就是堆和栈的完美结合。其实，面向对象方式的程序与以前结构化的程序在执行上没有任何区别。但是，面向对象的引入，使得对待问题的思考方式发生了改变，而更接近于自然方式的思考。当我们把对象拆开，你会发现，对象的属性其实就是数据，存放在堆中；而对象的行为（方法），就是运行逻辑，放在栈中。我们在编写对象的时候，其实即编写了数据结构，也编写的处理数据的逻辑。不得不承认，面向对象的设计，确实很美。</p>
<h6 id="堆和栈的区别"><a href="#堆和栈的区别" class="headerlink" title="堆和栈的区别"></a>堆和栈的区别</h6><p>Main函数就是栈的起始点。</p>
<p>堆中存的是对象。栈中存的是基本数据类型和堆中对象的引用。一个对象的大小是不可估计的，或者说是可以动态变化的，但是在栈中，一个对象只对应了一个4btye的引用（堆栈分离的好处 ）。</p>
<p>基本类型放堆中是因为其占用的空间一般是1~8个字节——需要空间比较少，而且因为是基本类型，所以不会出现动态增长的情况——长度固定，因此栈中存储就够了。可以这么说，基本类型和对象的引用都是存放在栈中，而且都是几个字节的一个数，因此在程序运行时，他们的处理方式是统一的。</p>
<p>​    <strong>程序运行永远都是在栈中进行的</strong>，因而参数传递时，只存在传递基本类型和对象引用的问题。不会直接传对象本身。Java在方法调用传递参数时，因为没有指针，所以它都是进行传值调用（这点可以参考C的传值调用）。</p>
<p>​    堆和栈中，栈是程序运行最根本的东西。程序运行可以没有堆，但是不能没有栈。而堆是为栈进行数据存储服务，说白了堆就是一块共享的内存。不过，正是因为堆和栈的分离的思想，才使得Java的垃圾回收成为可能。</p>
<p>​    Java中，栈的大小通过-Xss来设置，当栈中存储数据比较多时，需要适当调大这个值，否则会出现java.lang.StackOverflowError异常。常见的出现这个异常的是无法返回的递归，因为此时栈中保存的信息都是方法返回的记录点。</p>
<h2 id="Java对象的大小"><a href="#Java对象的大小" class="headerlink" title="Java对象的大小"></a>Java对象的大小</h2><p>基本数据的类型的大小是固定的，这里就不多说了。对于非基本类型的Java对象，其大小就值得商榷。</p>
<h6 id="普通类"><a href="#普通类" class="headerlink" title="普通类"></a>普通类</h6><p>在Java中，一个空Object对象的大小是8byte，这个大小只是保存堆中一个没有任何属性的对象的大小。看下面语句：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Object ob = <span class="keyword">new</span> Object();</span><br></pre></td></tr></table></figure>
<p>​    它所占的空间为：4byte+8byte。4byte是上面部分所说的Java栈中保存引用的所需要的空间。而那8byte则是Java堆中对象的信息。因为所有的Java非基本类型的对象都需要默认继承Object对象，因此不论什么样的Java对象，其大小都必须是大于8byte。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Class NewObject &#123;</span><br><span class="line">    <span class="keyword">int</span> count;</span><br><span class="line">    <span class="keyword">boolean</span> flag;</span><br><span class="line">    Object ob;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​    其大小为：空对象大小(8byte)+int大小(4byte)+Boolean大小(1byte)+空Object引用的大小(4byte)=17byte。但是因为Java在对对象内存分配时都是以8的整数倍来分，因此大于17byte的最接近8的整数倍的是24，因此此对象的大小为24byte。</p>
<h6 id="基本类型的包装类型的大小"><a href="#基本类型的包装类型的大小" class="headerlink" title="基本类型的包装类型的大小"></a>基本类型的包装类型的大小</h6><p>​    因为这种包装类型已经成为对象了，因此需要把他们作为对象来看待。包装类型的大小至少是12byte（声明一个空Object至少需要的空间），而且12byte没有包含任何有效信息，同时，因为Java对象大小是8的整数倍，因此一个基本类型包装类的大小至少是16byte。这个内存占用是很恐怖的，它是使用基本类型的N倍（N&gt;2），有些类型的内存占用更是夸张（随便想下就知道了）。因此，可能的话应尽量少使用包装类。在JDK5.0以后，因为加入了自动类型装换，因此，Java虚拟机会在存储方面进行相应的优化。</p>
<h2 id="引用类型"><a href="#引用类型" class="headerlink" title="引用类型"></a>引用类型</h2><p>对象引用类型分为强引用、软引用、弱引用和虚引用。</p>
<h6 id="强引用"><a href="#强引用" class="headerlink" title="强引用:"></a>强引用:</h6><p>就是我们一般声明对象是时虚拟机生成的引用，强引用环境下，垃圾回收时需要严格判断当前对象是否被强引用，如果被强引用，则不会被垃圾回收</p>
<h6 id="软引用"><a href="#软引用" class="headerlink" title="软引用:"></a>软引用:</h6><p>软引用一般被做为缓存来使用。与强引用的区别是，软引用在垃圾回收时，虚拟机会根据当前系统的剩余内存来决定是否对软引用进行回收。如果剩余内存比较紧张，则虚拟机会回收软引用所引用的空间；如果剩余内存相对富裕，则不会进行回收。换句话说，虚拟机在发生OutOfMemory时，肯定是没有软引用存在的。</p>
<h6 id="弱引用"><a href="#弱引用" class="headerlink" title="弱引用:"></a>弱引用:</h6><p>弱引用与软引用类似，都是作为缓存来使用。但与软引用不同，弱引用在进行垃圾回收时，是一定会被回收掉的，因此其生命周期只存在于一个垃圾回收周期内。</p>
<p>强引用不用说，我们系统一般在使用时都是用的强引用。而“软引用”和“弱引用”比较少见。他们一般被作为缓存使用，而且一般是在内存大小比较受限的情况下做为缓存。因为如果内存足够大的话，可以直接使用强引用作为缓存即可，同时可控性更高。因而，他们常见的是被使用在桌面应用系统的缓存。</p>
<h2 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h2><h3 id="按照基本回收策略"><a href="#按照基本回收策略" class="headerlink" title="按照基本回收策略"></a>按照基本回收策略</h3><h4 id="引用计数（Reference-Counting）"><a href="#引用计数（Reference-Counting）" class="headerlink" title="引用计数（Reference Counting）:"></a>引用计数（Reference Counting）:</h4><p>比较古老的回收算法。原理是此对象有一个引用，即增加一个计数，删除一个引用则减少一个计数。垃圾回收时，只用收集计数为0的对象。此算法最致命的是无法处理循环引用的问题。</p>
<h4 id="标记-清除（Mark-Sweep）"><a href="#标记-清除（Mark-Sweep）" class="headerlink" title="标记-清除（Mark-Sweep）:"></a>标记-清除（Mark-Sweep）:</h4><p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning002.png" alt="JVM Tuning 002"></p>
<p>​    此算法执行分两阶段。第一阶段从引用根节点开始标记所有被引用的对象，第二阶段遍历整个堆，把未标记的对象清除。此算法需要暂停整个应用，同时，会产生内存碎片。</p>
<h4 id="复制（Copying）"><a href="#复制（Copying）" class="headerlink" title="复制（Copying）:"></a>复制（Copying）:</h4><p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning003.png" alt="JVM Tuning 003"></p>
<p>​    此算法把内存空间划为两个相等的区域，每次只使用其中一个区域。垃圾回收时，遍历当前使用区域，把正在使用中的对象复制到另外一个区域中。次算法每次只处理正在使用中的对象，因此复制成本比较小，同时复制过去以后还能进行相应的内存整理，不会出现“碎片”问题。当然，此算法的缺点也是很明显的，就是需要两倍内存空间。</p>
<h4 id="标记-整理（Mark-Compact）"><a href="#标记-整理（Mark-Compact）" class="headerlink" title="标记-整理（Mark-Compact）:"></a>标记-整理（Mark-Compact）:</h4><p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning004.png" alt="JVM Tuning 004"></p>
<p>此算法结合了“标记-清除”和“复制”两个算法的优点。也是分两阶段，第一阶段从根节点开始标记所有被引用对象，第二阶段遍历整个堆，把清除未标记对象并且把存活对象“压缩”到堆的其中一块，按顺序排放。此算法避免了“标记-清除”的碎片问题，同时也避免了“复制”算法的空间问题。</p>
<h3 id="按分区对待的方式分"><a href="#按分区对待的方式分" class="headerlink" title="按分区对待的方式分"></a>按分区对待的方式分</h3><h4 id="增量收集（Incremental-Collecting）"><a href="#增量收集（Incremental-Collecting）" class="headerlink" title="增量收集（Incremental Collecting）"></a>增量收集（Incremental Collecting）</h4><p>实时垃圾回收算法，即：在应用进行的同时进行垃圾回收。不知道什么原因JDK5.0中的收集器没有使用这种算法的。</p>
<h4 id="分代收集（Generational-Collecting）"><a href="#分代收集（Generational-Collecting）" class="headerlink" title="分代收集（Generational Collecting）"></a>分代收集（Generational Collecting）</h4><p>基于对对象生命周期分析后得出的垃圾回收算法。把对象分为年青代、年老代、持久代，对不同生命周期的对象使用不同的算法（上述方式中的一个）进行回收。现在的垃圾回收器（从J2SE1.2开始）都是使用此算法的。</p>
<h3 id="按系统线程分"><a href="#按系统线程分" class="headerlink" title="按系统线程分"></a>按系统线程分</h3><p>串行收集</p>
<p>串行收集使用单线程处理所有垃圾回收工作, 因为无需多线程交互，实现容易，而且效率比较高。但是，其局限性也比较明显，即无法使用多处理器的优势，所以此收集适合单处理器机器。当然，此收集器也可以用在小数据量（100M左右）情况下的多处理器机器上。</p>
<p>并行收集</p>
<p>并行收集使用多线程处理垃圾回收工作，因而速度快，效率高。而且理论上CPU数目越多，越能体现出并行收集器的优势。</p>
<p>并发收集</p>
<p>相对于串行收集和并行收集而言，前面两个在进行垃圾回收工作时，需要暂停整个运行环境，而只有垃圾回收程序在运行，因此，系统在垃圾回收时会有明显的暂停，而且暂停时间会因为堆越大而越长。</p>
<h2 id="区分垃圾"><a href="#区分垃圾" class="headerlink" title="区分垃圾"></a>区分垃圾</h2><p>上面说到的“引用计数”法，通过统计控制生成对象和删除对象时的引用数来判断。垃圾回收程序收集计数为0的对象即可。但是这种方法无法解决循环引用。所以，后来实现的垃圾判断算法中，都是从程序运行的根节点出发，遍历整个对象引用，查找存活的对象。那么在这种方式的实现中，垃圾回收从哪儿开始的呢？即，从哪儿开始查找哪些对象是正在被当前系统使用的。上面分析的堆和栈的区别，其中栈是真正进行程序执行地方，所以要获取哪些对象正在被使用，则需要从Java栈开始。同时，一个栈是与一个线程对应的，因此，如果有多个线程的话，则必须对这些线程对应的所有的栈进行检查。</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning005.png" alt="JVM Tuning 005"></p>
<p>同时，除了栈外，还有系统运行时的寄存器等，也是存储程序运行数据的。这样，以栈或寄存器中的引用为起点，我们可以找到堆中的对象，又从这些对象找到对堆中其他对象的引用，这种引用逐步扩展，最终以null引用或者基本类型结束，这样就形成了一颗以Java栈中引用所对应的对象为根节点的一颗对象树，如果栈中有多个引用，则最终会形成多颗对象树。在这些对象树上的对象，都是当前系统运行所需要的对象，不能被垃圾回收。而其他剩余对象，则可以视为无法被引用到的对象，可以被当做垃圾进行回收。</p>
<p>因此，垃圾回收的起点是一些根对象（java栈, 静态变量, 寄存器…）。而最简单的Java栈就是Java程序执行的main函数。这种回收方式，也是上面提到的“标记-清除”的回收方式</p>
<h2 id="处理碎片"><a href="#处理碎片" class="headerlink" title="处理碎片"></a>处理碎片</h2><p>​    由于不同Java对象存活时间是不一定的，因此，在程序运行一段时间以后，如果不进行内存整理，就会出现零散的内存碎片。碎片最直接的问题就是会导致无法分配大块的内存空间，以及程序运行效率降低。所以，在上面提到的基本垃圾回收算法中，“复制”方式和“标记-整理”方式，都可以解决碎片的问题。</p>
<h2 id="如何解决同时存在的对象创建和对象回收问题"><a href="#如何解决同时存在的对象创建和对象回收问题" class="headerlink" title="如何解决同时存在的对象创建和对象回收问题"></a>如何解决同时存在的对象创建和对象回收问题</h2><p>垃圾回收线程是回收内存的，而程序运行线程则是消耗（或分配）内存的，一个回收内存，一个分配内存，从这点看，两者是矛盾的。因此，在现有的垃圾回收方式中，要进行垃圾回收前，一般都需要暂停整个应用（即：暂停内存的分配），然后进行垃圾回收，回收完成后再继续应用。这种实现方式是最直接，而且最有效的解决二者矛盾的方式。</p>
<p>但是这种方式有一个很明显的弊端，就是当堆空间持续增大时，垃圾回收的时间也将会相应的持续增大，对应应用暂停的时间也会相应的增大。一些对相应时间要求很高的应用，比如最大暂停时间要求是几百毫秒，那么当堆空间大于几个G时，就很有可能超过这个限制，在这种情况下，垃圾回收将会成为系统运行的一个瓶颈。为解决这种矛盾，有了并发垃圾回收算法，使用这种算法，垃圾回收线程与程序运行线程同时运行。在这种方式下，解决了暂停的问题，但是因为需要在新生成对象的同时又要回收对象，算法复杂性会大大增加，系统的处理能力也会相应降低，同时，“碎片”问题将会比较难解决。</p>
<h2 id="为什么要分代"><a href="#为什么要分代" class="headerlink" title="为什么要分代"></a>为什么要分代</h2><p>分代的垃圾回收策略，是基于这样一个事实：不同的对象的生命周期是不一样的。因此，不同生命周期的对象可以采取不同的收集方式，以便提高回收效率。</p>
<p>在Java程序运行的过程中，会产生大量的对象，其中有些对象是与业务信息相关，比如Http请求中的Session对象、线程、Socket连接，这类对象跟业务直接挂钩，因此生命周期比较长。但是还有一些对象，主要是程序运行过程中生成的临时变量，这些对象生命周期会比较短，比如：String对象，由于其不变类的特性，系统会产生大量的这些对象，有些对象甚至只用一次即可回收。</p>
<p>试想，在不进行对象存活时间区分的情况下，每次垃圾回收都是对整个堆空间进行回收，花费时间相对会长，同时，因为每次回收都需要遍历所有存活对象，但实际上，对于生命周期长的对象而言，这种遍历是没有效果的，因为可能进行了很多次遍历，但是他们依旧存在。因此，分代垃圾回收采用分治的思想，进行代的划分，把不同生命周期的对象放在不同代上，不同代上采用最适合它的垃圾回收方式进行回收。</p>
<h2 id="如何分代"><a href="#如何分代" class="headerlink" title="如何分代"></a>如何分代<img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning006.png" alt="JVM Tuning 006"></h2><p>如图所示：</p>
<p>虚拟机中的共划分为三个代：年轻代（Young Generation）、年老点（Old Generation）和持久代（Permanent Generation）。其中持久代主要存放的是Java类的类信息，与垃圾收集要收集的Java对象关系不大。年轻代和年老代的划分是对垃圾收集影响比较大的。</p>
<p>年轻代:</p>
<p>所有新生成的对象首先都是放在年轻代的。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。年轻代分三个区。一个Eden区，两个Survivor区(一般而言)。大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到Survivor区（两个中的一个），当这个Survivor区满时，此区的存活对象将被复制到另外一个Survivor区，当这个Survivor去也满了的时候，从第一个Survivor区复制过来的并且此时还存活的对象，将被复制“年老区(Tenured)”。需要注意，Survivor的两个区是对称的，没先后关系，所以同一个区中可能同时存在从Eden复制过来 对象，和从前一个Survivor复制过来的对象，而复制到年老区的只有从第一个Survivor去过来的对象。而且，Survivor区总有一个是空的。同时，根据程序需要，Survivor区是可以配置为多个的（多于两个），这样可以增加对象在年轻代中的存在时间，减少被放到年老代的可能。</p>
<p>年老代:</p>
<p>在年轻代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。</p>
<p>持久代:</p>
<p>用于存放静态文件，如今Java类、方法等。持久代对垃圾回收没有显著影响，但是有些应用可能动态生成或者调用一些class，例如Hibernate等，在这种时候需要设置一个比较大的持久代空间来存放这些运行过程中新增的类。持久代大小通过-XX:MaxPermSize=进行设置。</p>
<h2 id="什么情况下触发垃圾回收"><a href="#什么情况下触发垃圾回收" class="headerlink" title="什么情况下触发垃圾回收"></a>什么情况下触发垃圾回收</h2><p>由于对象进行了分代处理，因此垃圾回收区域、时间也不一样。GC有两种类型：Scavenge GC和Full GC。</p>
<p>Scavenge GC</p>
<p>一般情况下，当新对象生成，并且在Eden申请空间失败时，就会触发Scavenge GC，对Eden区域进行GC，清除非存活对象，并且把尚且存活的对象移动到Survivor区。然后整理Survivor的两个区。这种方式的GC是对年轻代的Eden区进行，不会影响到年老代。因为大部分对象都是从Eden区开始的，同时Eden区不会分配的很大，所以Eden区的GC会频繁进行。因而，一般在这里需要使用速度快、效率高的算法，使Eden去能尽快空闲出来。</p>
<p>Full GC</p>
<p>对整个堆进行整理，包括Young、Tenured和Perm。Full GC因为需要对整个对进行回收，所以比Scavenge GC要慢，因此应该尽可能减少Full GC的次数。在对JVM调优的过程中，很大一部分工作就是对于FullGC的调节。有如下原因可能导致Full GC：</p>
<p>· 年老代（Tenured）被写满<br>· 持久代（Perm）被写满<br>· System.gc()被显示调用<br>·上一次GC之后Heap的各域分配策略动态变化</p>
<h2 id="分代垃圾回收流程示意"><a href="#分代垃圾回收流程示意" class="headerlink" title="分代垃圾回收流程示意"></a>分代垃圾回收流程示意</h2><p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning007.png" alt="JVM Tuning 007"></p>
<p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning008.png" alt="JVM Tuning 008"></p>
<p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning009.png" alt="JVM Tuning 009"></p>
<p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning010.png" alt="JVM Tuning 010"></p>
<h2 id="选择合适的垃圾收集算法"><a href="#选择合适的垃圾收集算法" class="headerlink" title="选择合适的垃圾收集算法"></a>选择合适的垃圾收集算法</h2><p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning011.png" alt="JVM Tuning 011"></p>
<p>用单线程处理所有垃圾回收工作，因为无需多线程交互，所以效率比较高。但是，也无法使用多处理器的优势，所以此收集器适合单处理器机器。当然，此收集器也可以用在小数据量（100M左右）情况下的多处理器机器上。可以使用-XX:+UseSerialGC打开。</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning012.png" alt="JVM Tuning 012"></p>
<p>对年轻代进行并行垃圾回收，因此可以减少垃圾回收时间。一般在多线程多处理器机器上使用。使用-XX:+UseParallelGC.打开。并行收集器在J2SE5.0第六6更新上引入，在Java SE6.0中进行了增强–可以对年老代进行并行收集。如果年老代不使用并发收集的话，默认是使用单线程进行垃圾回收，因此会制约扩展能力。使用-XX:+UseParallelOldGC打开。</p>
<p>使用-XX:ParallelGCThreads=设置并行垃圾回收的线程数。此值可以设置与机器处理器数量相等。</p>
<p>此收集器可以进行如下配置：</p>
<blockquote>
<p>最大垃圾回收暂停:指定垃圾回收时的最长暂停时间，通过-XX:MaxGCPauseMillis=<n><n>指定。&gt;<n><n>为毫秒.如果指定了此值的话，堆大小和垃圾回收相关参数会进行调整以达到指定值。设定此值可能会减少应用的吞吐量。</n></n></n></n></p>
<p>吞吐量:吞吐量为垃圾回收时间与非垃圾回收时间的比值，通过-XX:GCTimeRatio=<n><n>来设定，公&gt;式为1/（1+N）。例如，-XX:GCTimeRatio=19时，表示5%的时间用于垃圾回收。默认情况为99，即&gt;1%的时间用于垃圾回收。</n></n></p>
</blockquote>
<p>并发收集器</p>
<p>可以保证大部分工作都并发进行（应用不停止），垃圾回收只暂停很少的时间，此收集器适合对响应时间要求比较高的中、大规模应用。使用-XX:+UseConcMarkSweepGC打开。</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning013.png" alt="JVM Tuning 013"></p>
<p>并发收集器主要减少年老代的暂停时间，他在应用不停止的情况下使用独立的垃圾回收线程，跟踪可达对象。在每个年老代垃圾回收周期中，在收集初期并发收集器 会对整个应用进行简短的暂停，在收集中还会再暂停一次。第二次暂停会比第一次稍长，在此过程中多个线程同时进行垃圾回收工作。</p>
<p>并发收集器使用处理器换来短暂的停顿时间。在一个N个处理器的系统上，并发收集部分使用K/N个可用处理器进行回收，一般情况下1&lt;=K&lt;=N/4。</p>
<p>在只有一个处理器的主机上使用并发收集器，设置为incremental mode模式也可获得较短的停顿时间。</p>
<p>浮动垃圾：由于在应用运行的同时进行垃圾回收，所以有些垃圾可能在垃圾回收进行完成时产生，这样就造成了“Floating Garbage”，这些垃圾需要在下次垃圾回收周期时才能回收掉。所以，并发收集器一般需要20%的预留空间用于这些浮动垃圾。</p>
<p>Concurrent Mode Failure：并发收集器在应用运行时进行收集，所以需要保证堆在垃圾回收的这段时间有足够的空间供程序使用，否则，垃圾回收还未完成，堆空间先满了。这种情况下将会发生“并发模式失败”，此时整个应用将会暂停，进行垃圾回收。</p>
<p>启动并发收集器：因为并发收集在应用运行时进行收集，所以必须保证收集完成之前有足够的内存空间供程序使用，否则会出现“Concurrent Mode Failure”。通过设置-XX:CMSInitiatingOccupancyFraction=指定还有多少剩余堆时开始执行并发收集</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>串行处理器：</p>
<ul>
<li>适用情况：数据量比较小（100M左右）；单处理器下并且对响应时间无要求的应用。</li>
<li>缺点：只能用于小型应用</li>
</ul>
<p>并行处理器：</p>
<ul>
<li>适用情况：“对吞吐量有高要求”，多CPU、对应用响应时间无要求的中、大型应用。举例：后台处理、科学计算。</li>
<li>缺点：垃圾收集过程中应用响应时间可能加长</li>
</ul>
<p>并发处理器：</p>
<ul>
<li>适用情况：“对响应时间有高要求”，多CPU、对应用响应时间有较高要求的中、大型应用。举例：Web服务器/应用服务器、电信交换、集成开发环境。</li>
</ul>
<p>以下配置主要针对分代垃圾回收算法而言。<br>##堆大小设置</p>
<p>年轻代的设置很关键<br>JVM中最大堆大小有三方面限制：相关操作系统的数据模型（32-bt还是64-bit）限制；系统的可用虚拟内存限制；系统的可用物理内存限制。32位系统下，一般限制在1.5G~2G；64为操作系统对内存无限制。在Windows Server 2003 系统，3.5G物理内存，JDK5.0下测试，最大可设置为1478m。<br>典型设置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">java -Xmx3550m -Xms3550m -Xmn2g –Xss128k</span><br><span class="line"></span><br><span class="line">-Xmx3550m：设置JVM最大可用内存为3550M。</span><br><span class="line"></span><br><span class="line">-Xms3550m：设置JVM促使内存为3550m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。</span><br><span class="line"></span><br><span class="line">-Xmn2g：设置年轻代大小为2G。整个堆大小=年轻代大小 + 年老代大小 + 持久代大小。持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。</span><br><span class="line"></span><br><span class="line">-Xss128k：设置每个线程的堆栈大小。JDK5.0以后每个线程堆栈大小为1M，以前每个线程堆栈大小为256K。更具应用的线程所需内存大小进行调整。在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">java -Xmx3550m -Xms3550m -Xss128k -XX:NewRatio=4 -XX:SurvivorRatio=4 -XX:MaxPermSize=16m -XX:MaxTenuringThreshold=0</span><br><span class="line"></span><br><span class="line">-XX:NewRatio=4:设置年轻代（包括Eden和两个Survivor区）与年老代的比值（除去持久代）。设置为4，则年轻代与年老代所占比值为1：4，年轻代占整个堆栈的1/5</span><br><span class="line"></span><br><span class="line">-XX:SurvivorRatio=4：设置年轻代中Eden区与Survivor区的大小比值。设置为4，则两个Survivor区与一个Eden区的比值为2:4，一个Survivor区占整个年轻代的1/6</span><br><span class="line"></span><br><span class="line">-XX:MaxPermSize=16m:设置持久代大小为16m。</span><br><span class="line"></span><br><span class="line">-XX:MaxTenuringThreshold=0：设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。</span><br></pre></td></tr></table></figure>
<h2 id="回收器选择"><a href="#回收器选择" class="headerlink" title="回收器选择"></a>回收器选择</h2><p>JVM给了三种选择：串行收集器、并行收集器、并发收集器，但是串行收集器只适用于小数据量的情况，所以这里的选择主要针对并行收集器和并发收集器。默认情况下，JDK5.0以前都是使用串行收集器，如果想使用其他收集器需要在启动时加入相应参数。JDK5.0以后，JVM会根据当前<a href="http://docs.oracle.com/javase/1.5.0/docs/guide/vm/server-class.html" target="_blank" rel="noopener">系统配置</a>进行判断。</p>
<p>吞吐量优先的并行收集器</p>
<p>如上文所述，并行收集器主要以到达一定的吞吐量为目标，适用于科学技术和后台处理等。</p>
<h4 id="典型配置："><a href="#典型配置：" class="headerlink" title="典型配置："></a>典型配置：</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">java -Xmx3800m -Xms3800m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads=<span class="number">20</span></span><br><span class="line"></span><br><span class="line">-XX:+UseParallelGC：选择垃圾收集器为并行收集器。此配置仅对年轻代有效。即上述配置下，年轻代使用并发收集，而年老代仍旧使用串行收集。</span><br><span class="line"></span><br><span class="line">-XX:ParallelGCThreads=<span class="number">20</span>：配置并行收集器的线程数，即：同时多少个线程一起进行垃圾回收。此值最好配置与处理器数目相等。</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads=<span class="number">20</span> -XX:+UseParallelOldGC</span><br><span class="line"></span><br><span class="line">-XX:+UseParallelOldGC：配置年老代垃圾收集方式为并行收集。JDK6.0支持对年老代并行收集。</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC  -XX:MaxGCPauseMillis=<span class="number">100</span></span><br><span class="line"></span><br><span class="line">-XX:MaxGCPauseMillis=<span class="number">100</span>:设置每次年轻代垃圾回收的最长时间，如果无法满足此时间，JVM会自动调整年轻代大小，以满足此值。</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">n java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC  -XX:MaxGCPauseMillis=<span class="number">100</span> -XX:+UseAdaptiveSizePolicy</span><br><span class="line"></span><br><span class="line">-XX:+UseAdaptiveSizePolicy：设置此选项后，并行收集器会自动选择年轻代区大小和相应的Survivor区比例，以达到目标系统规定的最低相应时间或者收集频率等，此值建议使用并行收集器时，一直打开。</span><br></pre></td></tr></table></figure>
<p>响应时间优先的并发收集器</p>
<p>如上文所述，并发收集器主要是保证系统的响应时间，减少垃圾收集时的停顿时间。适用于应用服务器、电信领域等。</p>
<h4 id="典型配置：-1"><a href="#典型配置：-1" class="headerlink" title="典型配置："></a>典型配置：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:ParallelGCThreads=20 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC</span><br><span class="line"></span><br><span class="line">-XX:+UseConcMarkSweepGC：设置年老代为并发收集。测试中配置这个以后，-XX:NewRatio=4的配置失效了，原因不明。所以，此时年轻代大小最好用-Xmn设置。</span><br><span class="line"></span><br><span class="line">-XX:+UseParNewGC: 设置年轻代为并行收集。可与CMS收集同时使用。JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此值。</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseConcMarkSweepGC -XX:CMSFullGCsBeforeCompaction=<span class="number">5</span> -XX:+UseCMSCompactAtFullCollection</span><br><span class="line"></span><br><span class="line">-XX:CMSFullGCsBeforeCompaction：由于并发收集器不对内存空间进行压缩、整理，所以运行一段时间以后会产生“碎片”，使得运行效率降低。此值设置运行多少次GC以后对内存空间进行压缩、整理。</span><br><span class="line"></span><br><span class="line">-XX:+UseCMSCompactAtFullCollection：打开对年老代的压缩。可能会影响性能，但是可以消除碎片</span><br></pre></td></tr></table></figure>
<h2 id="辅助信息"><a href="#辅助信息" class="headerlink" title="辅助信息"></a>辅助信息</h2><p>JVM提供了大量命令行参数，打印信息，供调试使用。主要有以下一些：</p>
<p>-XX:+PrintGC：输出形式：[GC 118250K-&gt;113543K(130112K), 0.0094143 secs] [Full GC 121376K-&gt;10414K(130112K), 0.0650971 secs]</p>
<p>-XX:+PrintGCDetails：输出形式：[GC [DefNew: 8614K-&gt;781K(9088K), 0.0123035 secs] 118250K-&gt;113543K(130112K), 0.0124633 secs] [GC [DefNew: 8614K-&gt;8614K(9088K), 0.0000665 secs][Tenured: 112761K-&gt;10414K(121024K), 0.0433488 secs] 121376K-&gt;10414K(130112K), 0.0436268 secs]</p>
<p>-XX:+PrintGCTimeStamps -XX:+PrintGC：PrintGCTimeStamps可与上面两个混合使用<br>输出形式：11.851: [GC 98328K-&gt;93620K(130112K), 0.0082960 secs]</p>
<p>-XX:+PrintGCApplicationConcurrentTime：打印每次垃圾回收前，程序未中断的执行时间。可与上面混合使用。输出形式：Application time: 0.5291524 seconds</p>
<p>-XX:+PrintGCApplicationStoppedTime：打印垃圾回收期间程序暂停的时间。可与上面混合使用。输出形式：Total time for which application threads were stopped: 0.0468229 seconds</p>
<p>-XX:PrintHeapAtGC: 打印GC前后的详细堆栈信息。输出形式：</p>
<p>34.702: [GC {Heap before gc invocations=7:<br>def new generation total 55296K, used 52568K [0x1ebd0000, 0x227d0000, 0x227d0000)<br>eden space 49152K, 99% used [0x1ebd0000, 0x21bce430, 0x21bd0000)<br>from space 6144K, 55% used [0x221d0000, 0x22527e10, 0x227d0000)<br>to space 6144K, 0% used [0x21bd0000, 0x21bd0000, 0x221d0000)<br>tenured generation total 69632K, used 2696K [0x227d0000, 0x26bd0000, 0x26bd0000)<br>the space 69632K, 3% used [0x227d0000, 0x22a720f8, 0x22a72200, 0x26bd0000)<br>compacting perm gen total 8192K, used 2898K [0x26bd0000, 0x273d0000, 0x2abd0000)<br>the space 8192K, 35% used [0x26bd0000, 0x26ea4ba8, 0x26ea4c00, 0x273d0000)<br>ro space 8192K, 66% used [0x2abd0000, 0x2b12bcc0, 0x2b12be00, 0x2b3d0000)<br>rw space 12288K, 46% used [0x2b3d0000, 0x2b972060, 0x2b972200, 0x2bfd0000)<br>34.735: [DefNew: 52568K-&gt;3433K(55296K), 0.0072126 secs] 55264K-&gt;6615K(124928K)Heap after gc invocations=8:<br>def new generation total 55296K, used 3433K [0x1ebd0000, 0x227d0000, 0x227d0000)<br>eden space 49152K, 0% used [0x1ebd0000, 0x1ebd0000, 0x21bd0000)<br>from space 6144K, 55% used [0x21bd0000, 0x21f2a5e8, 0x221d0000)<br>to space 6144K, 0% used [0x221d0000, 0x221d0000, 0x227d0000)<br>tenured generation total 69632K, used 3182K [0x227d0000, 0x26bd0000, 0x26bd0000)<br>the space 69632K, 4% used [0x227d0000, 0x22aeb958, 0x22aeba00, 0x26bd0000)<br>compacting perm gen total 8192K, used 2898K [0x26bd0000, 0x273d0000, 0x2abd0000)<br>the space 8192K, 35% used [0x26bd0000, 0x26ea4ba8, 0x26ea4c00, 0x273d0000)<br>ro space 8192K, 66% used [0x2abd0000, 0x2b12bcc0, 0x2b12be00, 0x2b3d0000)<br>rw space 12288K, 46% used [0x2b3d0000, 0x2b972060, 0x2b972200, 0x2bfd0000)<br>}<br>, 0.0757599 secs]</p>
<p>-Xloggc:filename:与上面几个配合使用，把相关日志信息记录到文件以便分析。</p>
<h2 id="常见配置汇总"><a href="#常见配置汇总" class="headerlink" title="常见配置汇总"></a>常见配置汇总</h2><p>堆设置<br>-Xms:初始堆大小<br>-Xmx:最大堆大小<br>-XX:NewSize=n:设置年轻代大小<br>-XX:NewRatio=n:设置年轻代和年老代的比值。如:为3，表示年轻代与年老代比值为1：3，年轻代占整个年轻代年老代和的1/4<br>-XX:SurvivorRatio=n:年轻代中Eden区与两个Survivor区的比值。注意Survivor区有两个。如：3，表示Eden：Survivor=3：2，一个Survivor区占整个年轻代的1/5<br>-XX:MaxPermSize=n:设置持久代大小</p>
<p>收集器设置<br>-XX:+UseSerialGC:设置串行收集器<br>-XX:+UseParallelGC:设置并行收集器<br>-XX:+UseParalledlOldGC:设置并行年老代收集器<br>-XX:+UseConcMarkSweepGC:设置并发收集器</p>
<p>垃圾回收统计信息<br>-XX:+PrintGC<br>-XX:+PrintGCDetails<br>-XX:+PrintGCTimeStamps<br>-Xloggc:filename</p>
<p>并行收集器设置<br>-XX:ParallelGCThreads=n:设置并行收集器收集时使用的CPU数。并行收集线程数。<br>-XX:MaxGCPauseMillis=n:设置并行收集最大暂停时间<br>-XX:GCTimeRatio=n:设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n)</p>
<p>并发收集器设置<br>-XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况。<br>-XX:ParallelGCThreads=n:设置并发收集器年轻代收集方式为并行收集时，使用的CPU数。并行收集线程数。</p>
<h2 id="调优总结"><a href="#调优总结" class="headerlink" title="调优总结"></a>调优总结</h2><p>年轻代大小选择</p>
<p>响应时间优先的应用：尽可能设大，直到接近系统的最低响应时间限制（根据实际情况选择）。在此种情况下，年轻代收集发生的频率也是最小的。同时，减少到达年老代的对象。</p>
<p>吞吐量优先的应用：尽可能的设置大，可能到达Gbit的程度。因为对响应时间没有要求，垃圾收集可以并行进行，一般适合8CPU以上的应用。</p>
<p>年老代大小选择</p>
<p>响应时间优先的应用：年老代使用并发收集器，所以其大小需要小心设置，一般要考虑并发会话率和会话持续时间等一些参数。如果堆设置小了，可以会造成内存碎片、高回收频率以及应用暂停而使用传统的标记清除方式；如果堆大了，则需要较长的收集时间。最优化的方案，一般需要参考以下数据获得：</p>
<ol>
<li>并发垃圾收集信息</li>
<li>持久代并发收集次数</li>
<li>传统GC信息</li>
<li>花在年轻代和年老代回收上的时间比例<br>减少年轻代和年老代花费的时间，一般会提高应用的效率</li>
</ol>
<p>吞吐量优先的应用</p>
<p>一般吞吐量优先的应用都有一个很大的年轻代和一个较小的年老代。原因是，这样可以尽可能回收掉大部分短期对象，减少中期的对象，而年老代尽存放长期存活对象。</p>
<p>较小堆引起的碎片问题</p>
<p>因为年老代的并发收集器使用标记、清除算法，所以不会对堆进行压缩。当收集器回收时，他会把相邻的空间进行合并，这样可以分配给较大的对象。但是，当堆空间较小时，运行一段时间以后，就会出现“碎片”，如果并发收集器找不到足够的空间，那么并发收集器将会停止，然后使用传统的标记、清除方式进行回收。如果出现“碎片”，可能需要进行如下配置：</p>
<ol>
<li>-XX:+UseCMSCompactAtFullCollection：使用并发收集器时，开启对年老代的压缩。</li>
<li>-XX:CMSFullGCsBeforeCompaction=0：上面配置开启的情况下，这里设置多少次Full GC后，对年老代进行压缩</li>
</ol>
<h2 id="垃圾回收的瓶颈"><a href="#垃圾回收的瓶颈" class="headerlink" title="垃圾回收的瓶颈"></a>垃圾回收的瓶颈</h2><p>传统分代垃圾回收方式，已经在一定程度上把垃圾回收给应用带来的负担降到了最小，把应用的吞吐量推到了一个极限。但是他无法解决的一个问题，就是Full GC所带来的应用暂停。在一些对实时性要求很高的应用场景下，GC暂停所带来的请求堆积和请求失败是无法接受的。这类应用可能要求请求的返回时间在几百甚至几十毫秒以内，如果分代垃圾回收方式要达到这个指标，只能把最大堆的设置限制在一个相对较小范围内，但是这样有限制了应用本身的处理能力，同样也是不可接收的。</p>
<p>分代垃圾回收方式确实也考虑了实时性要求而提供了并发回收器，支持最大暂停时间的设置，但是受限于分代垃圾回收的内存划分模型，其效果也不是很理想。</p>
<p>为了达到实时性的要求（其实Java语言最初的设计也是在嵌入式系统上的），一种新垃圾回收方式呼之欲出，它既支持短的暂停时间，又支持大的内存空间分配。可以很好的解决传统分代方式带来的问题。</p>
<h2 id="增量收集的演进"><a href="#增量收集的演进" class="headerlink" title="增量收集的演进"></a>增量收集的演进</h2><p>增量收集的方式在理论上可以解决传统分代方式带来的问题。增量收集把对堆空间划分成一系列内存块，使用时，先使用其中一部分（不会全部用完），垃圾收集时把之前用掉的部分中的存活对象再放到后面没有用的空间中，这样可以实现一直边使用边收集的效果，避免了传统分代方式整个使用完了再暂停的回收的情况。</p>
<p>当然，传统分代收集方式也提供了并发收集，但是他有一个很致命的地方，就是把整个堆做为一个内存块，这样一方面会造成碎片（无法压缩），另一方面他的每次收集都是对整个堆的收集，无法进行选择，在暂停时间的控制上还是很弱。而增量方式，通过内存空间的分块，恰恰可以解决上面问题。</p>
<h2 id="Garbage-Firest（G1）"><a href="#Garbage-Firest（G1）" class="headerlink" title="Garbage Firest（G1）"></a>Garbage Firest（G1）</h2><p>目标</p>
<p>从设计目标看G1完全是为了大型应用而准备的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">支持很大的堆</span><br><span class="line">高吞吐量</span><br><span class="line">  --支持多CPU和垃圾回收线程</span><br><span class="line">  --在主线程暂停的情况下，使用并行收集</span><br><span class="line">  --在主线程运行的情况下，使用并发收集</span><br><span class="line">实时目标：可配置在N毫秒内最多只占用M毫秒的时间进行垃圾回收</span><br></pre></td></tr></table></figure>
<p>当然G1要达到实时性的要求，相对传统的分代回收算法，在性能上会有一些损失。</p>
<p>算法详解</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning014.png" alt="JVM Tuning 014"></p>
<p>G1可谓博采众家之长，力求到达一种完美。他吸取了增量收集优点，把整个堆划分为一个一个等大小的区域（region）。内存的回收和划分都以region为单位；同时，他也吸取了CMS的特点，把这个垃圾回收过程分为几个阶段，分散一个垃圾回收过程；而且，G1也认同分代垃圾回收的思想，认为不同对象的生命周期不同，可以采取不同收集方式，因此，它也支持分代的垃圾回收。为了达到对回收时间的可预计性，G1在扫描了region以后，对其中的活跃对象的大小进行排序，首先会收集那些活跃对象小的region，以便快速回收空间（要复制的活跃对象少了），因为活跃对象小，里面可以认为多数都是垃圾，所以这种方式被称为Garbage First（G1）的垃圾回收算法，即：垃圾优先的回收。</p>
<h4 id="回收步骤："><a href="#回收步骤：" class="headerlink" title="回收步骤："></a>回收步骤：</h4><h4 id="初始标记（Initial-Marking）"><a href="#初始标记（Initial-Marking）" class="headerlink" title="初始标记（Initial Marking）"></a>初始标记（Initial Marking）</h4><p>G1对于每个region都保存了两个标识用的bitmap，一个为previous marking bitmap，一个为next marking bitmap，bitmap中包含了一个bit的地址信息来指向对象的起始点。</p>
<p>开始Initial Marking之前，首先并发的清空next marking bitmap，然后停止所有应用线程，并扫描标识出每个region中root可直接访问到的对象，将region中top的值放入next top at mark start（TAMS）中，之后恢复所有应用线程。</p>
<p>触发这个步骤执行的条件为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">G1定义了一个JVM Heap大小的百分比的阀值，称为h，另外还有一个H，H的值为(1-h)*Heap Size，目前这个h的值是固定的，后续G1也许会将其改为动态的，根据jvm的运行情况来动态的调整，在分代方式下，G1还定义了一个u以及soft limit，soft limit的值为H-u*Heap Size，当Heap中使用的内存超过了soft limit值时，就会在一次clean up执行完毕后在应用允许的GC暂停时间范围内尽快的执行此步骤；</span><br><span class="line"></span><br><span class="line">在pure方式下，G1将marking与clean up组成一个环，以便clean up能充分的使用marking的信息，当clean up开始回收时，首先回收能够带来最多内存空间的regions，当经过多次的clean up，回收到没多少空间的regions时，G1重新初始化一个新的marking与clean up构成的环。</span><br></pre></td></tr></table></figure>
<h4 id="并发标记（Concurrent-Marking）"><a href="#并发标记（Concurrent-Marking）" class="headerlink" title="并发标记（Concurrent Marking）"></a>并发标记（Concurrent Marking）</h4><p>按照之前Initial Marking扫描到的对象进行遍历，以识别这些对象的下层对象的活跃状态，对于在此期间应用线程并发修改的对象的以来关系则记录到remembered set logs中，新创建的对象则放入比top值更高的地址区间中，这些新创建的对象默认状态即为活跃的，同时修改top值。</p>
<h4 id="最终标记暂停（Final-Marking-Pause）"><a href="#最终标记暂停（Final-Marking-Pause）" class="headerlink" title="最终标记暂停（Final Marking Pause）"></a>最终标记暂停（Final Marking Pause）</h4><p>当应用线程的remembered set logs未满时，是不会放入filled RS buffers中的，在这样的情况下，这些remebered set logs中记录的card的修改就会被更新了，因此需要这一步，这一步要做的就是把应用线程中存在的remembered set logs的内容进行处理，并相应的修改remembered sets，这一步需要暂停应用，并行的运行。</p>
<h4 id="存活对象计算及清除（Live-Data-Counting-and-Cleanup）"><a href="#存活对象计算及清除（Live-Data-Counting-and-Cleanup）" class="headerlink" title="存活对象计算及清除（Live Data Counting and Cleanup）"></a>存活对象计算及清除（Live Data Counting and Cleanup）</h4><p>值得注意的是，在G1中，并不是说Final Marking Pause执行完了，就肯定执行Cleanup这步的，由于这步需要暂停应用，G1为了能够达到准实时的要求，需要根据用户指定的最大的GC造成的暂停时间来合理的规划什么时候执行Cleanup，另外还有几种情况也是会触发这个步骤的执行的：</p>
<p>G1采用的是复制方法来进行收集，必须保证每次的”to space”的空间都是够的，因此G1采取的策略是当已经使用的内存空间达到了H时，就执行Cleanup这个步骤；</p>
<p>对于full-young和partially-young的分代模式的G1而言，则还有情况会触发Cleanup的执行，full-young模式下，G1根据应用可接受的暂停时间、回收young regions需要消耗的时间来估算出一个yound regions的数量值，当JVM中分配对象的young regions的数量达到此值时，Cleanup就会执行；partially-young模式下，则会尽量频繁的在应用可接受的暂停时间范围内执行Cleanup，并最大限度的去执行non-young regions的Cleanup。</p>
<h2 id="JVM调优工具"><a href="#JVM调优工具" class="headerlink" title="JVM调优工具"></a>JVM调优工具</h2><p>Jconsole，jProfile，VisualVM</p>
<p>Jconsole : jdk自带，功能简单，但是可以在系统有一定负荷的情况下使用。对垃圾回收算法有很详细的跟踪。</p>
<p>JProfiler：商业软件，需要付费。功能强大。</p>
<p>VisualVM：JDK自带，功能强大，与JProfiler类似。推荐。</p>
<h2 id="如何调优"><a href="#如何调优" class="headerlink" title="如何调优"></a>如何调优</h2><p>观察内存释放情况、集合类检查、对象树</p>
<p>上面这些调优工具都提供了强大的功能，但是总的来说一般分为以下几类功能</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning015.png" alt="JVM Tuning 015"></p>
<p>可查看堆空间大小分配（年轻代、年老代、持久代分配）<br>提供即时的垃圾回收功能<br>垃圾监控（长时间监控回收情况）</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning016.png" alt="JVM Tuning 016"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看堆内类、对象信息查看：数量、类型等</span><br></pre></td></tr></table></figure>
<p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning017.png" alt="JVM Tuning 017"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">对象引用情况查看</span><br></pre></td></tr></table></figure>
<p>有了堆信息查看方面的功能，我们一般可以顺利解决以下问题：</p>
<ul>
<li>年老代年轻代大小划分是否合理</li>
<li>内存泄漏</li>
<li>垃圾回收算法设置是否合理</li>
</ul>
<h2 id="线程监控"><a href="#线程监控" class="headerlink" title="线程监控"></a>线程监控</h2><p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning018.png" alt="JVM Tuning 018"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">线程信息监控：系统线程数量。</span><br><span class="line">线程状态监控：各个线程都处在什么样的状态下</span><br></pre></td></tr></table></figure>
<p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning019.png" alt="JVM Tuning 019"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Dump线程详细信息：查看线程内部运行情况</span><br><span class="line">死锁检查</span><br></pre></td></tr></table></figure>
<p>热点分析</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning020.png" alt="JVM Tuning 020"></p>
<p>CPU热点：检查系统哪些方法占用的大量CPU时间</p>
<p>内存热点：检查哪些对象在系统中数量最大（一定时间内存活对象和销毁对象一起统计）</p>
<p>这两个东西对于系统优化很有帮助。我们可以根据找到的热点，有针对性的进行系统的瓶颈查找和进行系统优化，而不是漫无目的的进行所有代码的优化。</p>
<p>快照<br>快照是系统运行到某一时刻的一个定格。在我们进行调优的时候，不可能用眼睛去跟踪所有系统变化，依赖快照功能，我们就可以进行系统两个不同运行时刻，对象（或类、线程等）的不同，以便快速找到问题</p>
<p>举例说，我要检查系统进行垃圾回收以后，是否还有该收回的对象被遗漏下来的了。那么，我可以在进行垃圾回收前后，分别进行一次堆情况的快照，然后对比两次快照的对象情况。</p>
<h2 id="内存泄漏检查"><a href="#内存泄漏检查" class="headerlink" title="内存泄漏检查"></a>内存泄漏检查</h2><p>内存泄漏是比较常见的问题，而且解决方法也比较通用，这里可以重点说一下，而线程、热点方面的问题则是具体问题具体分析了。</p>
<p>内存泄漏一般可以理解为系统资源（各方面的资源，堆、栈、线程等）在错误使用的情况下，导致使用完毕的资源无法回收（或没有回收），从而导致新的资源分配请求无法完成，引起系统错误。</p>
<p>内存泄漏对系统危害比较大，因为他可以直接导致系统的崩溃。</p>
<p>需要区别一下，内存泄漏和系统超负荷两者是有区别的，虽然可能导致的最终结果是一样的。内存泄漏是用完的资源没有回收引起错误，而系统超负荷则是系统确实没有那么多资源可以分配了（其他的资源都在使用）。</p>
<p>年老代堆空间被占满</p>
<h4 id="异常：-java-lang-OutOfMemoryError-Java-heap-space"><a href="#异常：-java-lang-OutOfMemoryError-Java-heap-space" class="headerlink" title="异常： java.lang.OutOfMemoryError: Java heap space"></a>异常： java.lang.OutOfMemoryError: Java heap space</h4><p>说明：</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/andy-zhou/806435/o_Jvm_Tuning021.png" alt="JVM Tuning 021"></p>
<p>这是最典型的内存泄漏方式，简单说就是所有堆空间都被无法回收的垃圾对象占满，虚拟机无法再在分配新空间。<br>如上图所示，这是非常典型的内存泄漏的垃圾回收情况图。所有峰值部分都是一次垃圾回收点，所有谷底部分表示是一次垃圾回收后剩余的内存。连接所有谷底的点，可以发现一条由底到高的线，这说明，随时间的推移，系统的堆空间被不断占满，最终会占满整个堆空间。因此可以初步认为系统内部可能有内存泄漏。（上面的图仅供示例，在实际情况下收集数据的时间需要更长，比如几个小时或者几天）</p>
<p>解决：</p>
<p>这种方式解决起来也比较容易，一般就是根据垃圾回收前后情况对比，同时根据对象引用情况（常见的集合对象引用）分析，基本都可以找到泄漏点。</p>
<p>持久代被占满</p>
<h4 id="异常：java-lang-OutOfMemoryError-PermGen-space"><a href="#异常：java-lang-OutOfMemoryError-PermGen-space" class="headerlink" title="异常：java.lang.OutOfMemoryError: PermGen space"></a>异常：java.lang.OutOfMemoryError: PermGen space</h4><p>说明：</p>
<p>Perm空间被占满。无法为新的class分配存储空间而引发的异常。这个异常以前是没有的，但是在Java反射大量使用的今天这个异常比较常见了。主要原因就是大量动态反射生成的类不断被加载，最终导致Perm区被占满。</p>
<p>更可怕的是，不同的classLoader即便使用了相同的类，但是都会对其进行加载，相当于同一个东西，如果有N个classLoader那么他将会被加载N次。因此，某些情况下，这个问题基本视为无解。当然，存在大量classLoader和大量反射类的情况其实也不多。<br>解决：</p>
<ol>
<li>-XX:MaxPermSize=16m</li>
<li>换用JDK。比如JRocket。</li>
</ol>
<p>堆栈溢出</p>
<h4 id="异常：java-lang-StackOverflowError"><a href="#异常：java-lang-StackOverflowError" class="headerlink" title="异常：java.lang.StackOverflowError"></a>异常：java.lang.StackOverflowError</h4><p>说明：这个就不多说了，一般就是递归没返回，或者循环调用造成</p>
<p>线程堆栈满</p>
<p>异常：Fatal: Stack size too small</p>
<p>说明：java中一个线程的空间大小是有限制的。JDK5.0以后这个值是1M。与这个线程相关的数据将会保存在其中。但是当线程空间满了以后，将会出现上面异常。</p>
<p>解决：增加线程栈大小。-Xss2m。但这个配置无法解决根本问题，还要看代码部分是否有造成泄漏的部分。</p>
<p>系统内存被占满</p>
<h4 id="异常：java-lang-OutOfMemoryError-unable-to-create-new-native-thread"><a href="#异常：java-lang-OutOfMemoryError-unable-to-create-new-native-thread" class="headerlink" title="异常：java.lang.OutOfMemoryError: unable to create new native thread"></a>异常：java.lang.OutOfMemoryError: unable to create new native thread</h4><p>说明：</p>
<p>这个异常是由于操作系统没有足够的资源来产生这个线程造成的。系统创建线程时，除了要在Java堆中分配内存外，操作系统本身也需要分配资源来创建线程。因此，当线程数量大到一定程度以后，堆中或许还有空间，但是操作系统分配不出资源来了，就出现这个异常了。</p>
<p>分配给Java虚拟机的内存愈多，系统剩余的资源就越少，因此，当系统内存固定时，分配给Java虚拟机的内存越多，那么，系统总共能够产生的线程也就越少，两者成反比的关系。同时，可以通过修改-Xss来减少分配给单个线程的空间，也可以增加系统总共内生产的线程数。</p>
<p>解决：</p>
<ol>
<li>重新设计系统减少线程数量。</li>
<li>线程数量不能减少的情况下，通过-Xss减小单个线程大小。以便能生产更多的线程。</li>
</ol>
<h2 id="垃圾回收的悖论"><a href="#垃圾回收的悖论" class="headerlink" title="垃圾回收的悖论"></a>垃圾回收的悖论</h2><p>​    所谓“成也萧何败萧何”。Java的垃圾回收确实带来了很多好处，为开发带来了便利。但是在一些高性能、高并发的情况下，垃圾回收确成为了制约Java应用的瓶颈。目前JDK的垃圾回收算法，始终无法解决垃圾回收时的暂停问题，因为这个暂停严重影响了程序的相应时间，造成拥塞或堆积。这也是后续JDK增加G1算法的一个重要原因。</p>
<p>​    当然，上面是从技术角度出发解决垃圾回收带来的问题，但是从系统设计方面我们就需要问一下了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">· 我们需要分配如此大的内存空间给应用吗？</span><br><span class="line">· 我们是否能够通过有效使用内存而不是通过扩大内存的方式来设计我们的系统呢？</span><br></pre></td></tr></table></figure>
<h2 id="我们的内存中都放了什么"><a href="#我们的内存中都放了什么" class="headerlink" title="我们的内存中都放了什么"></a>我们的内存中都放了什么</h2><p>​    内存中需要放什么呢？个人认为，内存中需要放的是你的应用需要在不久的将来再次用到到的东西。想想看，如果你在将来不用这些东西，何必放内存呢？放文件、数据库不是更好？这些东西一般包括：</p>
<ol>
<li>系统运行时业务相关的数据。比如web应用中的session、即时消息的session等。这些数据一般在一个用户访问周期或者一个使用过程中都需要存在。</li>
<li>缓存。缓存就比较多了，你所要快速访问的都可以放这里面。其实上面的业务数据也可以理解为一种缓存。</li>
<li>线程。</li>
</ol>
<p>​        我们是不是可以这么认为，如果我们不把业务数据和缓存放在JVM中，或者把他们独立出来，那么Java应用使用时所需的内存将会大大减少，同时垃圾回收时间也会相应减少。我认为这是可能的。</p>
<h2 id="解决之道"><a href="#解决之道" class="headerlink" title="解决之道"></a>解决之道</h2><h6 id="数据库、文件系统"><a href="#数据库、文件系统" class="headerlink" title="数据库、文件系统"></a>数据库、文件系统</h6><p>​    把所有数据都放入数据库或者文件系统，这是一种最为简单的方式。在这种方式下，Java应用的内存基本上等于处理一次峰值并发请求所需的内存。数据的获取都在每次请求时从数据库和文件系统中获取。也可以理解为，一次业务访问以后，所有对象都可以进行回收了。</p>
<p>​    这是一种内存使用最有效的方式，但是从应用角度来说，这种方式很低效。</p>
<h6 id="内存-硬盘映射"><a href="#内存-硬盘映射" class="headerlink" title="内存-硬盘映射"></a>内存-硬盘映射</h6><p>​    上面的问题是因为我们使用了文件系统带来了低效。但是如果我们不是读写硬盘，而是写内存的话效率将会提高很多。</p>
<p>​    数据库和文件系统都是实实在在进行了持久化，但是当我们并不需要这样持久化的时候，我们可以做一些变通——把内存当硬盘使。</p>
<p>​    内存-硬盘映射很好很强大，既用了缓存又对Java应用的内存使用又没有影响。Java应用还是Java应用，他只知道读写的还是文件，但是实际上是内存。</p>
<p>​    这种方式兼得的Java应用与缓存两方面的好处。memcached的广泛使用也正是这一类的代表。</p>
<h6 id="同一机器部署多个JVM"><a href="#同一机器部署多个JVM" class="headerlink" title="同一机器部署多个JVM"></a>同一机器部署多个JVM</h6><p>​    这也是一种很好的方式，可以分为纵拆和横拆。纵拆可以理解为把Java应用划分为不同模块，各个模块使用一个独立的Java进程。而横拆则是同样功能的应用部署多个JVM。</p>
<p>​    通过部署多个JVM，可以把每个JVM的内存控制一个垃圾回收可以忍受的范围内即可。但是这相当于进行了分布式的处理，其额外带来的复杂性也是需要评估的。另外，也有支持分布式的这种JVM可以考虑，不要要钱哦：）</p>
<h6 id="程序控制的对象生命周期"><a href="#程序控制的对象生命周期" class="headerlink" title="程序控制的对象生命周期"></a>程序控制的对象生命周期</h6><p>​    这种方式是理想当中的方式，目前的虚拟机还没有，纯属假设。即：考虑由编程方式配置哪些对象在垃圾收集过程中可以直接跳过，减少垃圾回收线程遍历标记的时间。</p>
<p>​    这种方式相当于在编程的时候告诉虚拟机某些对象你可以在*时间后在进行收集或者由代码标识可以收集了（类似C、C++），在这之前你即便去遍历他也是没有效果的，他肯定是还在被引用的。</p>
<p>​    这种方式如果JVM可以实现，个人认为将是一个飞跃，Java即有了垃圾回收的优势，又有了C、C++对内存的可控性。</p>
<h6 id="线程分配"><a href="#线程分配" class="headerlink" title="线程分配"></a>线程分配</h6><p>​    Java的阻塞式的线程模型基本上可以抛弃了，目前成熟的NIO框架也比较多了。阻塞式IO带来的问题是线程数量的线性增长，而NIO则可以转换成为常数线程。因此，对于服务端的应用而言，NIO还是唯一选择。不过，JDK7中为我们带来的AIO是否能让人眼前一亮呢？我们拭目以待。</p>
<h6 id="其他的JDK"><a href="#其他的JDK" class="headerlink" title="其他的JDK"></a>其他的JDK</h6><p>​    本文说的都是Sun的JDK，目前常见的JDK还有JRocket和IBM的JDK。其中JRocket在IO方面比Sun的高很多，不过Sun JDK6.0以后提高也很大。而且JRocket在垃圾回收方面，也具有优势，其可设置垃圾回收的最大暂停时间也是很吸引人的。不过，系统Sun的G1实现以后，在这方面会有一个质的飞跃。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://tongdaxia.github.io/2019/05/22/JVM调优/" data-id="cjvykca5h00003k8zoqkg6kep" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-连接池技术" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/05/22/连接池技术/" class="article-date">
  <time datetime="2019-05-22T00:20:18.475Z" itemprop="datePublished">2019-05-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="连接池技术"><a href="#连接池技术" class="headerlink" title="连接池技术"></a>连接池技术</h1><p>JDBC是一个规范，遵循JDBC接口规范，各个数据库厂家各自实现自己的驱动程序(Driver)。</p>
<p>在标准JDBC对应用的接口中，并没有提供资源的管理方法。所以，缺省的资源管理由应用自己负责。虽然在JDBC规范中，多次提及资源的关闭/回收及其他的合理运用。但最稳妥的方式，还是为应用提供有效的管理手段。所以，JDBC为第三方应用服务器（Application Server）提供了一个由数据库厂家实现的管理标准接口：连接缓冲(connection pooling)。引入了连接池( Connection Pool )的概念 ，也就是以缓冲池的机制管理数据库的资源。</p>
<h6 id="ConnectionPool-主要作用："><a href="#ConnectionPool-主要作用：" class="headerlink" title="ConnectionPool 主要作用："></a>ConnectionPool 主要作用：</h6><p>在一定数量上限范围内，控制管理Connection，Statement和ResultSet。</p>
<p>数据资源往往是瓶颈资源，不同的应用都会访问同一数据源。其中某个应用耗尽了数据库资源后，意味其他的应用也无法正常运行。因此，ConnectionPool的第一个任务是<strong>限制每个应用或系统可以拥有的最大资源</strong>。也就是确定连接池的大小(PoolSize)。</p>
<p>在连接池的大小(PoolSize)范围内，<strong>最大限度地使用资源</strong>，缩短数据库访问的使用周期。许多数据库中，连接（Connection）并不是资源的最小单元，控制Statement资源比Connection更重要。</p>
<p>以Oracle为例：<br>每申请一个连接（Connection）会在物理网络（如 TCP/IP网络）上建立一个用于通讯的连接，在此连接上还可以申请一定数量的Statement。同一连接可提供的活跃Statement数量可以达到几百。在节约网络资源的同时，缩短了每次会话周期（物理连接的建立是个费时的操作）。让几十、几百个Statement只占用同一个物理连接， 发挥数据库原有的优点。</p>
<h6 id="连接池管理逻辑"><a href="#连接池管理逻辑" class="headerlink" title="连接池管理逻辑"></a>连接池管理逻辑</h6><p>当客户请求数据库连接时，首先查看连接池中是否有空闲连接（指当前没有分配出去的连接）。如果存在空闲连接，则把连接分配给客户并作相应处理（即标记该连接为正在使用，<a href="https://baike.baidu.com/item/%E5%BC%95%E7%94%A8%E8%AE%A1%E6%95%B0" target="_blank" rel="noopener">引用计数</a>加1）。如果没有空闲连接，则查看当前所开的连接数是不是已经达到maxConn（<a href="https://baike.baidu.com/item/%E6%9C%80%E5%A4%A7%E8%BF%9E%E6%8E%A5%E6%95%B0" target="_blank" rel="noopener">最大连接数</a>），如果没达到就重新创建一个连接给请求的客户；如果达到就按设定的maxWaitTime（最大等待时间）进行等待，如果等待maxWaitTime后仍没有空闲连接，就抛出无空闲连接的异常给用户。</p>
<p>当客户释放数据库连接时，先判断该连接的引用次数是否超过了规定值，如果超过就删除该连接，并判断当前连接池内总的连接数是否小于minConn（最小连接数），若小于就将连接池充满；如果没超过就将该连接标记为开放状态，可供再次复用。可以看出正是这套策略保证了数据库连接的有效复用，避免频繁地建立、释放连接所带来的系统资源开销。</p>
<h6 id="事务处理"><a href="#事务处理" class="headerlink" title="事务处理"></a>事务处理</h6><p>Connection本身具有提供了对于事务的支持，可以通过设置Connection的AutoCommit属性为false，显式的调用 commit或rollback方法来实现。但是要安全、高效的进行连接复用，就必须提供相应的事务支持机制。方法是：采用显式的事务支撑方法，每一个事务独占一个连接。这种方法可以大大降低对于事务处理的复杂性，并且又不会妨碍连接的复用。</p>
<p>连接管理服务提供了显式的事务]开始、结束（commit 或rollback）声明，以及一个事务 注册表 ，用于登记事务发起者和事务使用的连接的对应关系，通过该表，使用事务的部分和连接管理部分就隔离开，因为该表是在运行时根据实际的调用情况动态生成的。事务使用的连接在该事务运行中不能被复用。在实现中,用户标识 是通过使用者所在的线程来标识的。后面的所有对于数据库的访问都是通过查找该注册表，使用已经分配的连接来完成的。当事务结束时，从注册表中删除相应表项。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://tongdaxia.github.io/2019/05/22/连接池技术/" data-id="cjvykca5w00013k8zptmwlt67" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/05/22/hello-world/" class="article-date">
  <time datetime="2019-05-22T00:20:18.475Z" itemprop="datePublished">2019-05-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/05/22/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://tongdaxia.github.io/2019/05/22/hello-world/" data-id="cjvykca5w00023k8zshgl5fje" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-分布式事务" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/05/22/分布式事务/" class="article-date">
  <time datetime="2019-05-22T00:20:18.475Z" itemprop="datePublished">2019-05-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>分布式系统的核心就是处理各种异常情况，这也是分布式系统复杂的地方，因为分布式的网络环境很复杂，这种“断电”故障要比单机多很多，所以我们在做分布式系统的时候，最先考虑的就是这种情况。这些异常可能有 机器宕机、网络异常、消息丢失、消息乱序、数据错误、不可靠的TCP、存储数据丢失、其他异常等等…</p>
<h4 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h4><ul>
<li>一致性(Consistency) ： 客户端知道一系列的操作都会同时发生(生效)</li>
<li>可用性(Availability) ： 每个操作都必须以可预期的响应结束</li>
<li>分区容错性(Partition tolerance) ： 即使出现单个组件无法可用,操作依然可以完成</li>
</ul>
<h4 id="BASE理论"><a href="#BASE理论" class="headerlink" title="BASE理论"></a>BASE理论</h4><p>在分布式系统中，我们往往追求的是可用性，它的重要程序比一致性要高，那么如何实现高可用性呢？ 前人已经给我们提出来了另外一个理论，就是BASE理论，它是用来对CAP定理进行进一步扩充的。BASE理论指的是：</p>
<ul>
<li>Basically Available（基本可用）</li>
<li>Soft state（软状态）</li>
<li>Eventually consistent（最终一致性）</li>
</ul>
<p><strong>我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性</strong>（Eventual consistency）。</p>
<p>解决方案：</p>
<p>和上一节中提到的数据库XA事务一样，两阶段提交就是使用XA协议的原理，我们可以从下面这个图的流程来很容易的看出中间的一些比如commit和abort的细节。</p>
<p><img src="F:\笔记\笔记\notes\250417-20171016132145537-970496141.png" alt="250417-20171016132145537-970496141"></p>
<p>两阶段提交这种解决方案属于牺牲了一部分可用性来换取的一致性。在实现方面，在 .NET 中，可以借助 TransactionScop 提供的 API 来编程实现分布式系统中的两阶段提交，比如WCF中就有实现这部分功能。不过在多服务器之间，需要依赖于DTC来完成事务一致性，Windows下微软搞的有MSDTC服务，Linux下就比较悲剧了。</p>
<p>另外说一句，TransactionScop 默认不能用于异步方法之间事务一致，因为事务上下文是存储于当前线程中的，所以如果是在异步方法，需要显式的传递事务上下文。</p>
<p><strong>优点：</strong> 尽量保证了数据的强一致，适合对数据强一致要求很高的关键领域。（其实也不能100%保证强一致）</p>
<p><strong>缺点：</strong> 实现复杂，牺牲了可用性，对性能影响较大，不适合高并发高性能场景，如果分布式系统跨接口调用，目前 .NET 界还没有实现方案。</p>
<h4 id="二、补偿事务（TCC）"><a href="#二、补偿事务（TCC）" class="headerlink" title="二、补偿事务（TCC）"></a>二、补偿事务（TCC）</h4><p>TCC 其实就是采用的补偿机制，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。它分为三个阶段：</p>
<ul>
<li>Try 阶段主要是对业务系统做检测及资源预留</li>
<li>Confirm 阶段主要是对业务系统做确认提交，Try阶段执行成功并开始执行 Confirm阶段时，默认 Confirm阶段是不会出错的。即：只要Try成功，Confirm一定成功。</li>
<li>Cancel 阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。</li>
</ul>
<p>举个例子，假入 Bob 要向 Smith 转账，思路大概是：<br>我们有一个本地方法，里面依次调用<br>1、首先在 Try 阶段，要先调用远程接口把 Smith 和 Bob 的钱给冻结起来。<br>2、在 Confirm 阶段，执行远程调用的转账的操作，转账成功进行解冻。<br>3、如果第2步执行成功，那么转账成功，如果第二步执行失败，则调用远程冻结接口对应的解冻方法 (Cancel)。</p>
<p><strong>优点：</strong> 跟2PC比起来，实现以及流程相对简单了一些，但数据的一致性比2PC也要差一些</p>
<p><strong>缺点：</strong> 缺点还是比较明显的，在2,3步中都有可能失败。TCC属于应用层的一种补偿方式，所以需要程序员在实现的时候多写很多补偿的代码，在一些场景中，一些业务流程可能用TCC不太好定义及处理。</p>
<h4 id="三、本地消息表（异步确保）"><a href="#三、本地消息表（异步确保）" class="headerlink" title="三、本地消息表（异步确保）"></a>三、本地消息表（异步确保）</h4><p>本地消息表这种实现方式应该是业界使用最多的，其核心思想是将分布式事务拆分成本地事务进行处理，这种思路是来源于ebay。我们可以从下面的流程图中看出其中的一些细节：</p>
<p><img src="https://images2017.cnblogs.com/blog/250417/201710/250417-20171016141237443-2074834323.png" alt="img"></p>
<p>基本思路就是：</p>
<p>消息生产方，需要额外建一个消息表，并记录消息发送状态。消息表和业务数据要在一个事务里提交，也就是说他们要在一个数据库里面。然后消息会经过MQ发送到消息的消费方。如果消息发送失败，会进行重试发送。</p>
<p>消息消费方，需要处理这个消息，并完成自己的业务逻辑。此时如果本地事务处理成功，表明已经处理成功了，如果处理失败，那么就会重试执行。如果是业务上面的失败，可以给生产方发送一个业务补偿消息，通知生产方进行回滚等操作。</p>
<p>生产方和消费方定时扫描本地消息表，把还没处理完成的消息或者失败的消息再发送一遍。如果有靠谱的自动对账补账逻辑，这种方案还是非常实用的。</p>
<p>这种方案遵循BASE理论，采用的是最终一致性，笔者认为是这几种方案里面比较适合实际业务场景的，即不会出现像2PC那样复杂的实现(当调用链很长的时候，2PC的可用性是非常低的)，也不会像TCC那样可能出现确认或者回滚不了的情况。</p>
<p><strong>优点：</strong> 一种非常经典的实现，避免了分布式事务，实现了最终一致性。在 .NET中 有现成的解决方案。</p>
<p><strong>缺点：</strong> 消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。</p>
<h4 id="四、MQ-事务消息"><a href="#四、MQ-事务消息" class="headerlink" title="四、MQ 事务消息"></a>四、MQ 事务消息</h4><p>有一些第三方的MQ是支持事务消息的，比如RocketMQ，他们支持事务消息的方式也是类似于采用的二阶段提交，但是市面上一些主流的MQ都是不支持事务消息的，比如 RabbitMQ 和 Kafka 都不支持。</p>
<p>以阿里的 RocketMQ 中间件为例，其思路大致为：</p>
<p>第一阶段Prepared消息，会拿到消息的地址。<br>第二阶段执行本地事务，第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。</p>
<p>也就是说在业务方法内要想消息队列提交两次请求，一次发送消息和一次确认消息。如果确认消息发送失败了RocketMQ会定期扫描消息集群中的事务消息，这时候发现了Prepared消息，它会向消息发送者确认，所以生产方需要实现一个check接口，RocketMQ会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。</p>
<p><img src="https://images2017.cnblogs.com/blog/250417/201710/250417-20171016203840240-13953078.png" alt="img"></p>
<p>遗憾的是，RocketMQ并没有 .NET 客户端。有关 RocketMQ的更多消息，大家可以查看<a href="http://www.jianshu.com/p/453c6e7ff81c" target="_blank" rel="noopener">这篇博客</a></p>
<p><strong>优点：</strong> 实现了最终一致性，不需要依赖本地数据库事务。</p>
<p><strong>缺点：</strong> 实现难度大，主流MQ不支持，没有.NET客户端，RocketMQ事务消息部分代码也未开源。</p>
<h4 id="五、Sagas-事务模型"><a href="#五、Sagas-事务模型" class="headerlink" title="五、Sagas 事务模型"></a>五、Sagas 事务模型</h4><p>Saga事务模型又叫做长时间运行的事务（Long-running-transaction）, 它是由普林斯顿大学的H.Garcia-Molina等人提出，它描述的是另外一种在没有两阶段提交的的情况下解决分布式系统中复杂的业务事务问题。你可以在<a href="https://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf" target="_blank" rel="noopener">这里</a>看到 Sagas 相关论文。</p>
<p>我们这里说的是一种基于 Sagas 机制的工作流事务模型，这个模型的相关理论目前来说还是比较新的，以至于百度上几乎没有什么相关资料。</p>
<p>该模型其核心思想就是拆分分布式系统中的长事务为多个短事务，或者叫多个本地事务，然后由 Sagas 工作流引擎负责协调，如果整个流程正常结束，那么就算是业务成功完成，如果在这过程中实现失败，那么Sagas工作流引擎就会以相反的顺序调用补偿操作，重新进行业务回滚。</p>
<p>比如我们一次关于购买旅游套餐业务操作涉及到三个操作，他们分别是预定车辆，预定宾馆，预定机票，他们分别属于三个不同的远程接口。可能从我们程序的角度来说他们不属于一个事务，但是从业务角度来说是属于同一个事务的。</p>
<p><img src="https://images2017.cnblogs.com/blog/250417/201710/250417-20171016220040115-805407978.png" alt="img"></p>
<p>他们的执行顺序如上图所示，所以当发生失败时，会依次进行取消的补偿操作。</p>
<p>因为长事务被拆分了很多个业务流，所以 Sagas 事务模型最重要的一个部件就是工作流或者你也可以叫流程管理器（Process Manager），工作流引擎和Process Manager虽然不是同一个东西，但是在这里，他们的职责是相同的。在选择工作流引擎之后，最终的代码也许看起来是这样的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">SagaBuilder saga = SagaBuilder.newSaga(&quot;trip&quot;)</span><br><span class="line">        .activity(&quot;Reserve car&quot;, ReserveCarAdapter.class) </span><br><span class="line">        .compensationActivity(&quot;Cancel car&quot;, CancelCarAdapter.class) </span><br><span class="line">        .activity(&quot;Book hotel&quot;, BookHotelAdapter.class) </span><br><span class="line">        .compensationActivity(&quot;Cancel hotel&quot;, CancelHotelAdapter.class) </span><br><span class="line">        .activity(&quot;Book flight&quot;, BookFlightAdapter.class) </span><br><span class="line">        .compensationActivity(&quot;Cancel flight&quot;, CancelFlightAdapter.class) </span><br><span class="line">        .end()</span><br><span class="line">        .triggerCompensationOnAnyError();</span><br><span class="line"></span><br><span class="line">camunda.getRepositoryService().createDeployment() </span><br><span class="line">        .addModelInstance(saga.getModel()) </span><br><span class="line">        .deploy();</span><br></pre></td></tr></table></figure>
<p><a href="https://github.com/flowing/flowing-trip-booking-saga-c-sharp" target="_blank" rel="noopener">这里</a>有一个 C# 相关示例，有兴趣的同学可以看一下。</p>
<p>优缺点这里我们就不说了，因为这个理论比较新，目前市面上还没有什么解决方案，即使是 Java 领域，我也没有搜索的太多有用的信息。</p>
<h3 id="分布式事务解决方案：CAP"><a href="#分布式事务解决方案：CAP" class="headerlink" title="分布式事务解决方案：CAP"></a>分布式事务解决方案：CAP</h3><p>上面介绍的那些分布式事务的处理方案你在其他地方或许也可以看到，但是并没有相关的实际代码或者是开源代码，所以算不上什么干货，下面就放干货了。</p>
<p>在 .NET 领域，似乎没有什么现成的关于分布式事务的解决方案，或者说是有但未开源。具笔者了解，有一些公司内部其实是有这种解决方案的，但是也是作为公司的一个核心产品之一，并未开源…</p>
<p>鉴于以上原因，所以博主就打算自己写一个并且开源出来，所以从17年初就开始做这个事情，然后花了大半年的时间在一直不断完善，就是下面这个 CAP。</p>
<p>Github <a href="https://github.com/dotnetcore/CAP" target="_blank" rel="noopener">CAP</a>：这里的 CAP 就不是 CAP 理论了，而是一个 .NET 分布式事务解决方案的名字。</p>
<p>详细介绍：<br><a href="http://www.cnblogs.com/savorboard/p/cap.html" target="_blank" rel="noopener">http://www.cnblogs.com/savorboard/p/cap.html</a><br>相关文档：<br><a href="http://www.cnblogs.com/savorboard/p/cap-document.html" target="_blank" rel="noopener">http://www.cnblogs.com/savorboard/p/cap-document.html</a></p>
<p>夸张的是，这个解决方案是具有可视化界面（Dashboard）的，你可以很方面的看到哪些消息执行成功，哪些消息执行失败，到底是发送失败还是处理失败，一眼便知。</p>
<p>最夸张的是，这个解决方案的可视化界面还提供了<strong>实时动态图表</strong>，这样不但可以看到实时的消息发送及处理情况，连当前的系统处理消息的速度都可以看到，还可以看到过去24小时内的历史消息吞吐量。</p>
<p>最最夸张的是，这个解决方案的还帮你集成了 Consul 做分布式节点发现和注册还有心跳检查，你随时可以看到其他的节点的状况。</p>
<p>最最最夸张的是，你以为你看其他节点的数据要登录到其他节点的Dashboard控制台看？错了，你随便打开其中任意一个节点的Dashboard，点一下就可以切换到你想看的节点的控制台界面了，就像你看本地的数据一样，他们是完全去中心化的。</p>
<p>你以为这些就够了？不，远远不止：</p>
<ul>
<li>CAP 同时支持 RabbitMQ，Kafka 等消息队列</li>
<li>CAP 同时支持 SQL Server, MySql, PostgreSql 等数据库</li>
<li>CAP Dashboard 同时支持中文和英文界面双语言，妈妈再也不用担心我看不懂了</li>
<li>CAP 提供了丰富的接口可以供扩展，什么序列化了，自定义处理了，自定义发送了统统不在话下</li>
<li>CAP 基于MIT开源，你可以尽管拿去做二次开发。（记得保留MIT的License）</li>
</ul>
<p>这下你以为我说完了？ 不！</p>
<p>你完全可以把 CAP 当做一个 EventBus 来使用，CAP具有优秀的消息处理能力，不要担心瓶颈会在CAP，那是永远不可能， 因为你随时可以在配置中指定CAP处理的消息使用的进程数， 只要你的数据库配置足够高…</p>
<p>说了这么多，口干舌燥的，你不 <strong>Star</strong> 一下给个精神上的支持说不过去吧？ ^_^</p>
<p>2号传送门： <a href="https://github.com/dotnetcore/CAP" target="_blank" rel="noopener">https://github.com/dotnetcore/CAP</a></p>
<blockquote>
<p>不 Star 也没关系，我选择原谅你~</p>
</blockquote>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过本文我们了解到两个分布式系统的理论，他们分别是CAP和BASE 理论，同时我们也总结并对比了几种分布式分解方案的优缺点，分布式事务本身是一个技术难题，是没有一种完美的方案应对所有场景的，具体还是要根据业务场景去抉择吧。 然后我们介绍了一种基于本地消息的的分布式事务解决方案CAP。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://tongdaxia.github.io/2019/05/22/分布式事务/" data-id="cjvykca5w00033k8z2b2nu18u" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">五月 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/05/22/JVM调优/">(no title)</a>
          </li>
        
          <li>
            <a href="/2019/05/22/连接池技术/">(no title)</a>
          </li>
        
          <li>
            <a href="/2019/05/22/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2019/05/22/分布式事务/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Dear TongDaxia<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>